{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Viva Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos as listas para guardar as informações\n",
    "\n",
    "link_imovel=[] # nesta lista iremos guardar a url\n",
    "address=[]     # nesta lista iremos guardar o endereço\n",
    "neighbor=[]    # nesta lista iremos guardar o bairro\n",
    "anunciante=[]  # nesta lista iremos guardar o anunciante \n",
    "area=[]        # nesta lista iremos guardar a area\n",
    "tipo=[]        # nesta lista iremos guardar o tipo de imóvel\n",
    "room=[]        # nesta lista iremos guardar a quantidade de quartos\n",
    "bath=[]        # nesta lista iremos guardar a quantidade de banheiros\n",
    "park=[]        # nesta lista iremos guardar a quantidade de vagas de garagem\n",
    "price=[]       # nesta lista iremos guardar o preço do imóvel\n",
    "\n",
    "# Ele irá solicitar quantas páginas você deseja coletar\n",
    "pages_number=int(input('Quantas paginas? '))\n",
    "# inicializa o tempo de execução\n",
    "tic = time.time()\n",
    "\n",
    "# Configure chromedriver\n",
    "# para executar, é necessário que você baixe o chromedriver e deixe ele na mesma pasta de execução, ou mude o path\n",
    "chromedriver = \"./chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "# Informe o link inicial para inicializar o scraping. Você pode trocar entre diversos filtros.\n",
    "# Este scraper foi desenvolvido para o filtro de alugueis na cidade de santa maria no rio grande do sul. \n",
    "# Pode acontecer das informações mudarem caso novos filtros sejam adicionados.\n",
    "link = f'https://www.vivareal.com.br/aluguel/sp/sao-paulo/?__vt=lnv:a&pagina=1'\n",
    "# link = f'https://www.vivareal.com.br/aluguel/rio-grande-do-sul/santa-maria/?pagina=1#onde=BR-Rio_Grande_do_Sul-NULL-Santa_Maria'\n",
    "driver.get(link)\n",
    "\n",
    "# Criando o loop entre as paginas do site\n",
    "for page in range(1,pages_number+1):\n",
    "   \n",
    "    # Definimos um sleep time para não sobrecarregar o site\n",
    "    time.sleep(15)\n",
    "    # coletamos todas as informações da página e transformamos em formato legivel\n",
    "    data = driver.execute_script(\"return document.getElementsByTagName('html')[0].innerHTML\")\n",
    "    soup_complete_source = BeautifulSoup(data.encode('utf-8'), \"lxml\")\n",
    "    \n",
    "    # identificamos todos os itens de card de imóveis\n",
    "    soup = soup_complete_source.find(class_='results-list js-results-list')    \n",
    "    \n",
    "\n",
    "    # Web-Scraping\n",
    "    # para cada elemento no conjunto de cards, colete:\n",
    "    for line in soup.findAll(class_=\"js-card-selector\"):\n",
    "        # colete o endereço completo e o bairro\n",
    "        try:\n",
    "            full_address=line.find(class_=\"property-card__address\").text.strip()\n",
    "            address.append(full_address.replace('\\n', '')) #Get all address\n",
    "            if full_address[:3]=='Rua' or full_address[:7]=='Avenida' or full_address[:8]=='Travessa' or full_address[:7]=='Alameda':\n",
    "                neighbor_first=full_address.strip().find('-')\n",
    "                neighbor_second=full_address.strip().find(',', neighbor_first)\n",
    "                if neighbor_second!=-1:\n",
    "                    neighbor_text=full_address.strip()[neighbor_first+2:neighbor_second]\n",
    "                    neighbor.append(neighbor_text) # Guarde na lista todos os bairros\n",
    "                else: # Bairro não encontrado\n",
    "                    neighbor_text='-'\n",
    "                    neighbor.append(neighbor_text) # Caso o bairro não seja encontrado\n",
    "            else:\n",
    "                get_comma=full_address.find(',')\n",
    "                if get_comma!=-1:\n",
    "                    neighbor_text=full_address[:get_comma]\n",
    "                    neighbor.append(neighbor_text) # Guarde na lista todos os bairros com problema de formatação provenientes do proprio website  \n",
    "                else:\n",
    "                    get_hif=full_address.find('-')\n",
    "                    neighbor_text=full_address[:get_hif]\n",
    "                    neighbor.append(neighbor_text)\n",
    "                    \n",
    "            # Coleta o link\n",
    "            full_link=line.find(class_='property-card__main-info').a.get('href')\n",
    "            link_imovel.append(full_link)\n",
    "                    \n",
    "            # Coleta o anunciante\n",
    "            full_anunciante=line.find(class_='property-card__account-link js-property-card-account-link').img.get('alt').title()\n",
    "            anunciante.append(full_anunciante)\n",
    "                    \n",
    "            # Coleta a área  \n",
    "            full_area=line.find(class_=\"property-card__detail-value js-property-card-value property-card__detail-area js-property-card-detail-area\").text.strip()\n",
    "            area.append(full_area)\n",
    "            \n",
    "            # Coleta tipologia\n",
    "            full_tipo = line.find(class_='property-card__title js-cardLink js-card-title').text.split()[0]\n",
    "            full_tipo=full_tipo.replace(' ','')\n",
    "            full_tipo=full_tipo.replace('\\n','')\n",
    "            tipo.append(full_tipo)\n",
    "\n",
    "            # Coleta numero de quartos\n",
    "            full_room=line.find(class_=\"property-card__detail-item property-card__detail-room js-property-detail-rooms\").text.strip()\n",
    "            full_room=full_room.replace(' ','')\n",
    "            full_room=full_room.replace('\\n','')\n",
    "            full_room=full_room.replace('Quartos','')\n",
    "            full_room=full_room.replace('Quarto','')\n",
    "            room.append(full_room) #Get apto's rooms\n",
    "\n",
    "            # Coleta numero de banheiros\n",
    "            full_bath=line.find(class_=\"property-card__detail-item property-card__detail-bathroom js-property-detail-bathroom\").text.strip()        \n",
    "            full_bath=full_bath.replace(' ','')\n",
    "            full_bath=full_bath.replace('\\n','')\n",
    "            full_bath=full_bath.replace('Banheiros','')\n",
    "            full_bath=full_bath.replace('Banheiro','')\n",
    "            bath.append(full_bath) #Get apto's Bathrooms\n",
    "\n",
    "            # Coleta numero de vagas de garagem\n",
    "            full_park=line.find(class_=\"property-card__detail-item property-card__detail-garage js-property-detail-garages\").text.strip()        \n",
    "            full_park=full_park.replace(' ','')\n",
    "            full_park=full_park.replace('\\n','')\n",
    "            full_park=full_park.replace('Vagas','')\n",
    "            full_park=full_park.replace('Vaga','')\n",
    "            park.append(full_park) #Get apto's parking lot\n",
    "\n",
    "            # Coleta preço\n",
    "            full_price=re.sub('[^0-9]','',line.find(class_=\"property-card__price js-property-card-prices js-property-card__price-small\").text.strip())\n",
    "            price.append(full_price) #Get apto's parking lot\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # condicional para parar de iterar entre pages\n",
    "    if page < pages_number:\n",
    "        receita = driver.find_element_by_xpath(f'//*[@id=\"js-site-main\"]/div[2]/div[1]/section/div[2]/div[2]/div/ul/li[9]/a')\n",
    "        receita.click()\n",
    "            \n",
    "# fecha o chromedriver\n",
    "driver.quit()\n",
    "\n",
    "# cria um dataframe pandas e salva como um arquivo CSV\n",
    "for i in range(0,len(neighbor)):\n",
    "    combinacao=[link_imovel[i],address[i],neighbor[i],anunciante[i],area[i],tipo[i],room[i],bath[i],park[i],price[i]]\n",
    "    df=pd.DataFrame(combinacao)\n",
    "    with open('VivaRealData.csv', 'a', encoding='utf-16', newline='') as f:\n",
    "        df.transpose().to_csv(f, encoding='iso-8859-1', header=False)\n",
    "\n",
    "# Tempo de execução\n",
    "toc = time.time()\n",
    "get_time=round(toc-tic,3)\n",
    "print('Finished in ' + str(get_time) + ' seconds')\n",
    "print(str(len(price))+' results!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
